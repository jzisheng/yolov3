{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"utils/\")\n",
    "import wv_util as wv\n",
    "from utils.dataset_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 601937/601937 [00:03<00:00, 165433.18it/s]\n"
     ]
    }
   ],
   "source": [
    "coords1, chips1, classes1 = wv.get_labels('/data/zjc4//xView_train.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:01, 144.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/data/zjc4/train_images/1395.tif'\n"
     ]
    }
   ],
   "source": [
    "import aug_util as aug\n",
    "import wv_util as wv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import tqdm\n",
    "import pickle\n",
    "import itertools\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "import imp\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import dataset_utils as du\n",
    "\n",
    "imp.reload(wv)\n",
    "imp.reload(du)\n",
    "\n",
    "import random\n",
    "np.random.seed(10)\n",
    "random.seed(10)\n",
    "unique_chips = np.unique(chips1)\n",
    "selected_images = np.random.choice(unique_chips,180)\n",
    "#selected_images = np.random.choice(unique_chips,10)\n",
    "idxs = np.isin(chips1,selected_images)\n",
    "\n",
    "# Input desired classes\n",
    "grouped_classes = [[77,73],[11,12],[13],[17,18,20,21],\n",
    "       [19,23,24,25,28,29,60,61,65,26],[41,42,50,40,44,45,47,49]]\n",
    "\n",
    "labels = [\"building and facility\" ,\"small aircraft\", \n",
    "          \"large aircraft\",\"vehicles\",\"bus\",\"boat\"]\n",
    "\n",
    "xdataset = du.XviewDataset(grouped_classes,labels, coords1[idxs],chips1[idxs],classes1[idxs])\n",
    "tif_names,distrbs = xdataset.splitTrainTest()\n",
    "dfs,gc = distrbs\n",
    "\n",
    "string_sets = [\"train\",\"valid\"]\n",
    "datum = list(zip(string_sets,tif_names))\n",
    "\n",
    "\"\"\"\n",
    "Generate darknet images for 30 cm\n",
    "\"\"\"\n",
    "# Deleting all old images\n",
    "os.system(\"rm /data/zjc4/chipped-30/data/images/*\")\n",
    "os.system(\"rm /data/zjc4/chipped-30/data/labels/*\")\n",
    "\n",
    "\n",
    "dnf = du.DarkNetFormatter(output_dir_ = \"/data/zjc4/chipped-30/data/\",\n",
    "                       input_dir_=\"/data/zjc4/\",\n",
    "                       coords_ = coords1[idxs],\n",
    "                       chips_ = chips1[idxs],\n",
    "                       classes_ = classes1[idxs],\n",
    "                       grouped_classes_=grouped_classes)\n",
    "dnf.transformDatum(datum,30,showImg=False,chipImage=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                       0        1\n",
       " 0  building and facility  54736.0\n",
       " 1         small aircraft     12.0\n",
       " 2         large aircraft    121.0\n",
       " 3               vehicles  32526.0\n",
       " 4                    bus   5756.0\n",
       " 5                   boat    611.0,                        0        1\n",
       " 0  building and facility  13114.0\n",
       " 1         small aircraft      1.0\n",
       " 2         large aircraft     22.0\n",
       " 3               vehicles   6988.0\n",
       " 4                    bus   1189.0\n",
       " 5                   boat    344.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/data/zjc4/train_images/1395.tif'\n"
     ]
    }
   ],
   "source": [
    "os.system(\"rm /data/zjc4/chipped-90/data/images/*\")\n",
    "os.system(\"rm /data/zjc4/chipped-90/data/labels/*\")\n",
    "\n",
    "\"\"\"\n",
    "Generate images for 90 cm\n",
    "\"\"\"\n",
    "dnf = du.DarkNetFormatter(output_dir_ = \"/data/zjc4/chipped-90/data/\",\n",
    "                       input_dir_=\"/data/zjc4/\",\n",
    "                       coords_ = coords1[idxs],\n",
    "                       chips_ = chips1[idxs],\n",
    "                       classes_ = classes1[idxs],\n",
    "                       grouped_classes_=grouped_classes)\n",
    "dnf.transformDatum(datum,90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do: try running the non chipped model on chipped images, and see how it performs on the test set\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "class XviewDataset():\n",
    "    def __init__(self,grouped_classes_,labels_,coords_,chips_,classes_):\n",
    "        self.grouped_classes = grouped_classes_\n",
    "        self.all_classes = list(itertools.chain.from_iterable(grouped_classes_))\n",
    "        \n",
    "        self.labels = labels_\n",
    "        self.chips = chips_        \n",
    "        self.coords = coords_\n",
    "        self.classes = classes_\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def getGroupedClassIdx(self,gcs,classLabel):\n",
    "        for idx,labels in enumerate(gcs):\n",
    "            if classLabel in labels:\n",
    "                return idx\n",
    "\n",
    "    def getGroupedTransformDict(self):\n",
    "        transDict = {}\n",
    "        for idx,grouped_class in enumerate(self.grouped_classes):\n",
    "            for label in (grouped_class):\n",
    "                #print(\"{} : {}\".format(idx,label))\n",
    "                transDict[label] = idx\n",
    "                pass\n",
    "            pass\n",
    "        return (transDict)\n",
    "        \n",
    "    def getAllGroupTransformDict(self):\n",
    "        #print(\"---\")\n",
    "        transDict = {}\n",
    "        for idx,label in enumerate(self.all_classes):\n",
    "            #print(\"{} : {}\".format(idx,label))\n",
    "            transDict[label] = idx\n",
    "        return (transDict)\n",
    "                \n",
    "    def getLabelCounts(self):\n",
    "        \"\"\" \n",
    "        given a chips and classes, returns dataframe of \n",
    "        new label groupings counts\n",
    "        \"\"\"\n",
    "        chip_names = np.unique(self.chips)\n",
    "        gcResults = np.zeros((len(chip_names),len(self.grouped_classes)))\n",
    "        allGcResults = np.zeros((len(chip_names),len(self.all_classes)))\n",
    "        \n",
    "        gcTransDict = self.getGroupedTransformDict()\n",
    "        allGcTransDict = self.getAllGroupTransformDict()\n",
    "        \n",
    "        chip_strs = []\n",
    "        for c_idx, c in tqdm.tqdm(enumerate(chip_names)):\n",
    "            chip_strs.append(c)\n",
    "            # Get all classes in this chip\n",
    "            classes_chip = self.classes[self.chips==c]\n",
    "            # Filter to only get selected classes\n",
    "            mask = np.isin(classes_chip,self.all_classes)\n",
    "            classes_chip = classes_chip[mask]\n",
    "            # Now group and count classes by new indexes\n",
    "            self.classesChipsCount(gcResults,classes_chip,gcTransDict,c_idx)\n",
    "            self.classesChipsCount(allGcResults,classes_chip,allGcTransDict,c_idx)\n",
    "            pass\n",
    "        chip_strs = np.array(chip_strs).reshape(-1,1)\n",
    "        return np.hstack((chip_strs,gcResults)),np.hstack((chip_strs,allGcResults))\n",
    "\n",
    "    def checkThreshold(self,distr1, distr2, thres):\n",
    "        if (len(distr1) != len(distr2)):\n",
    "            print(\"columns' numbers don't fit.\")\n",
    "            return -1\n",
    "        for i in range(len(distr1)):\n",
    "            diff = abs(distr1[i] - distr2[i])\n",
    "            if diff > thres:\n",
    "                return False\n",
    "        return True\n",
    "    def classesChipsCount(self,results,classes_chip,transDict,c_idx):\n",
    "        # Get counts for grouped classes\n",
    "        gcLabels = (np.array([transDict[x] for x in classes_chip]))\n",
    "        labels,counts = np.unique(gcLabels,return_counts=True)\n",
    "        # Put counts for tif in grouped classes\n",
    "        np.put(results[c_idx,:],labels.astype(np.int64),np.array(counts,dtype=np.int64))\n",
    "        pass\n",
    "    \n",
    "    def getDistribution(self,data, selected_indexes,getNum=False):\n",
    "        #print(data.astype(float))\n",
    "        res = (np.sum(np.array(data[selected_indexes,:].astype(float)),axis=0))\n",
    "        if(getNum): \n",
    "            dividend = 1\n",
    "        else: \n",
    "            dividend = np.sum(res,axis=0)\n",
    "        return (res/dividend)\n",
    "    \n",
    "    def findBalance(self,data, train_percent, thres,debug=False):\n",
    "        class_num = len(data[0])\n",
    "        for i in range(1000000):\n",
    "            tr_set, te_set = train_test_split(np.array(list(range(len(data)))),\\\n",
    "                                              test_size=0.5)\n",
    "            tr_d = self.getDistribution(data, tr_set)\n",
    "            te_d = self.getDistribution(data, te_set)\n",
    "            \n",
    "            tr_numd = self.getDistribution(data, tr_set,getNum=True)\n",
    "            te_numd = self.getDistribution(data, te_set,getNum=True)\n",
    "            check = self.checkThreshold(tr_d, te_d, thres)\n",
    "            if (check == True) or debug:\n",
    "                return (tr_set, te_set),(tr_numd,te_numd)\n",
    "            elif (check == -1):\n",
    "                return -1\n",
    "\n",
    "        return [], []\n",
    "    def indToTifName(self,data, inds):\n",
    "        res = []\n",
    "        for ind in inds:\n",
    "            res.append(data[ind][0])\n",
    "        return res\n",
    "    \n",
    "    def getClassList(self):\n",
    "        result = []\n",
    "        for idx,label in enumerate(self.all_classes):\n",
    "            temp = all_labels_dict[str(label)] \n",
    "            result.append(temp)\n",
    "        return result\n",
    "    \n",
    "    def getGroupedClassList(self):\n",
    "        result = []\n",
    "        for idx,labels in enumerate(self.grouped_classes):\n",
    "            temp = [self.labels[idx] for label in labels]\n",
    "            result.extend(temp)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def getResultsDistribution(self,labelCounts,tifNames):\n",
    "        mask = np.isin(labelCounts[:,0],tifNames)\n",
    "        result = ( np.array(labelCounts[mask,1:],dtype=float) )\n",
    "        result = np.sum(result,axis=0).reshape(-1,1)\n",
    "        np_agc = (np.array(self.getGroupedClassList()).reshape(-1,1))\n",
    "        np_gcIdx = np.array(self.getClassList()).reshape(-1,1)\n",
    "        df =  pd.DataFrame(np.hstack( (np_agc,np_gcIdx , result)))\n",
    "        df.columns = [\"grouped cls\",\"og label\",'count']\n",
    "        return df\n",
    "    \n",
    "    def splitTrainTest(self):\n",
    "        allGroupedClasses = []\n",
    "        for a in self.grouped_classes:\n",
    "            allGroupedClasses.extend(a)\n",
    "        #allLabelCounts = self.getLabelCounts()\n",
    "        labelCounts,allLabelCounts = self.getLabelCounts()\n",
    "        idxs,numd = self.findBalance(labelCounts[:,1:], 0.8, 0.1)\n",
    "        train_ind, test_ind = idxs\n",
    "        \n",
    "        train_tifs = self.indToTifName(labelCounts,train_ind)\n",
    "        test_tifs = self.indToTifName(labelCounts, test_ind)\n",
    "        \n",
    "        mask = (np.isin(allLabelCounts[:,0],train_tifs))\n",
    "        \n",
    "        df_train = (self.getResultsDistribution(allLabelCounts,train_tifs))\n",
    "        df_test = (self.getResultsDistribution(allLabelCounts,test_tifs))\n",
    "\n",
    "        gc_df_train = (pd.DataFrame(np.hstack(( np.array(self.labels).reshape(-1,1),\n",
    "                        numd[0].reshape(-1,1) )) ))\n",
    "        gc_df_test = (pd.DataFrame(np.hstack(( np.array(self.labels).reshape(-1,1),\n",
    "                        numd[1].reshape(-1,1) )) ))\n",
    "        return (train_tifs,test_tifs),((df_train,df_test),(gc_df_train,gc_df_test))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DarkNetFormatter():\n",
    "    def __init__(self,output_dir_,input_dir_,coords_,chips_,classes_,grouped_classes_):\n",
    "        self.output_dir = output_dir_\n",
    "        self.input_dir = input_dir_\n",
    "        self.chips = chips_        \n",
    "        self.coords = coords_\n",
    "        self.classes = classes_\n",
    "        self.grouped_classes = grouped_classes_\n",
    "        self.res_native=30\n",
    "        pass\n",
    "    \n",
    "    def filterClasses(self,chip_coords,chip_classes,grouped_classes):\n",
    "        filtered_classes = list(itertools.chain.from_iterable(self.grouped_classes))\n",
    "        mask = (np.isin(chip_classes,filtered_classes))\n",
    "        chip_coords, chip_classes = chip_coords[mask], chip_classes[mask]\n",
    "\n",
    "        for idx, g_cls in enumerate(self.grouped_classes):\n",
    "\n",
    "            mask = (np.isin(chip_classes,g_cls))\n",
    "            chip_classes[mask] = idx\n",
    "        return chip_coords,chip_classes\n",
    "        pass\n",
    "\n",
    "    def plotDarknetFmt(self,c_img,x_center,y_center,ws,hs,c_cls,szx,szy):\n",
    "        fig,ax = plt.subplots(1,figsize=(10,10))\n",
    "        ax.imshow(c_img)\n",
    "        for didx in range(c_cls.shape[0]):\n",
    "            x,y = x_center[didx]*szx,y_center[didx]*szy\n",
    "            w,h = ws[didx]*szx,hs[didx]*szy\n",
    "            x1,y1 = x-(w/2), y-(h/2)\n",
    "            w1,h1 = w,h\n",
    "            rect = patches.Rectangle((x1,y1),w1,h1,\\\n",
    "                                     linewidth=1,edgecolor='r',facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            pass\n",
    "        plt.show()\n",
    "        pass\n",
    "\n",
    "    def toDarknetFmt(self,c_box,c_cls,c_img,debug=False):\n",
    "        szx,szy,_ = c_img.shape\n",
    "        c_box[:,0],c_box[:,2] = c_box[:,0]/szx,c_box[:,2]/szx\n",
    "        c_box[:,1],c_box[:,3] = c_box[:,1]/szy,c_box[:,3]/szy\n",
    "        xmin,ymin,xmax,ymax = c_box[:,0],c_box[:,1],c_box[:,2],c_box[:,3]\n",
    "        ws,hs = (xmax-xmin), (ymax-ymin)\n",
    "        x_center, y_center = xmin+(ws/2),ymin+(hs/2)\n",
    "        # Visualize using mpl\n",
    "        if debug:\n",
    "            plotDarknetFmt(c_img,x_center,y_center,ws,hs,c_cls,szx,szy)\n",
    "        result = np.vstack((c_cls,x_center,y_center,ws,hs))\n",
    "        return result.T\n",
    "\n",
    "    def checkDir(self,filepath):\n",
    "        \"\"\" passed a filepath string, checks if it dne\n",
    "        if it does not exists makes directory\"\"\"\n",
    "        if not os.path.exists(filepath):\n",
    "            os.makedirs(filepath)\n",
    "        \n",
    "    def downsampleImage(self,img,res_native=30,res_out=120):\n",
    "        kernel_sz = int(0.5*(res_out/res_native))\n",
    "        scale_percent = res_native/res_out\n",
    "        width = int(img.shape[1] * scale_percent )\n",
    "        height = int(img.shape[0] * scale_percent)\n",
    "        dim = (width, height)\n",
    "        sigma = 0.3*((kernel_sz-1)*0.5 - 1) + 0.8\n",
    "        blur = cv.blur(img,(kernel_sz,kernel_sz),borderType=cv.BORDER_REFLECT)\n",
    "        resized = cv.resize(blur, dim, interpolation = cv.INTER_AREA)\n",
    "        return resized\n",
    "    \n",
    "    def parseChip(self,c_img, c_box, c_cls,img_num,c_dir,res_out=30,showImg = False):\n",
    "        # Parses chips, saves chip image, and also saves corresponding labels\n",
    "        fnames = []\n",
    "        \n",
    "        outputImgDir = \"{}labels/\".format(c_dir)\n",
    "        outputLabelDir = \"{}images/\".format(c_dir)\n",
    "        self.checkDir(outputImgDir)\n",
    "        self.checkDir(outputLabelDir)\n",
    "        \n",
    "        images = []\n",
    "        sboxes,sclasses,simgs = [],[],[]\n",
    "        \n",
    "        for c_idx in range(c_img.shape[0]):\n",
    "            c_name = \"{:06}_{:02}\".format(int(img_num), c_idx)\n",
    "            sbox,scls,simg = \\\n",
    "                c_box[c_idx],c_cls[c_idx],c_img[c_idx]\n",
    "            if showImg:\n",
    "                labelled = aug.draw_bboxes(simg,sbox)\n",
    "                plt.figure(figsize=(10,10))\n",
    "                plt.imshow(labelled)\n",
    "                plt.title(simg.shape)\n",
    "                plt.axis('off')\n",
    "                break\n",
    "\n",
    "            \n",
    "            # Change chip into darknet format, and save\n",
    "            result = self.toDarknetFmt(sbox,scls,simg)\n",
    "            ff_l = \"{}labels/{}.txt\".format(c_dir,c_name)\n",
    "            np.savetxt(ff_l, result, fmt='%i %1.6f %1.6f %1.6f %1.6f')\n",
    "            # Save image to specified dir\n",
    "            ff_i = \"{}images/{}.jpg\".format(c_dir,c_name)\n",
    "            \n",
    "            Image.fromarray(simg).save(ff_i)\n",
    "            # Append file name to list\n",
    "            fnames.append(\"{}images/{}.jpg\".format(c_dir,c_name))\n",
    "            pass\n",
    "        return fnames\n",
    "    \n",
    "    def exportChipImages(self,image_paths,c_dir,set_str,res_out=30,showImg=False):\n",
    "        fnames = []\n",
    "        #image_paths = sorted(image_paths)\n",
    "        for img_pth in image_paths:\n",
    "            try:\n",
    "                img_pth = self.input_dir+'train_images/'+img_pth\n",
    "                img_name = img_pth.split(\"/\")[-1]\n",
    "                img_num = img_name.split(\".\")[0]\n",
    "                arr = wv.get_image(img_pth)\n",
    "                chip_coords = self.coords[self.chips==img_name]\n",
    "                chip_classes = self.classes[self.chips==img_name].astype(np.int64)\n",
    "                chip_coords,chip_classes = \\\n",
    "                    self.filterClasses(chip_coords,chip_classes,self.grouped_classes)\n",
    "                # Code for downsampling the image\n",
    "                scale = self.res_native/res_out\n",
    "                if res_out != 30:\n",
    "                    arr = self.downsampleImage(arr,res_out=res_out)\n",
    "                    chip_coords = chip_coords*scale\n",
    "                # Chip the tif image into tiles\n",
    "                c_img, c_box, c_cls = wv.chip_image(img=arr, coords=chip_coords, \n",
    "                                                    classes=chip_classes, shape=(600,600))\n",
    "                if showImg:\n",
    "                    result = []\n",
    "                    for key in c_cls.keys():\n",
    "                        result.extend(c_cls[key])\n",
    "                    print(\"number of classes: {}\".format(len(result)))\n",
    "\n",
    "                    for i,img in enumerate(c_img):\n",
    "                        labelled = aug.draw_bboxes(c_img[i],c_box[i])\n",
    "                        plt.imshow(labelled)\n",
    "                        plt.axis('off')\n",
    "                        plt.show()\n",
    "                        pass\n",
    "                    break\n",
    "                    pass\n",
    "                \n",
    "                c_fnames = self.parseChip(c_img, c_box, c_cls, img_num, c_dir,res_out)\n",
    "                fnames.extend(c_fnames)\n",
    "\n",
    "            except FileNotFoundError as e:\n",
    "                print(e)\n",
    "                pass\n",
    "            pass\n",
    "        \n",
    "        lines = sorted(fnames)\n",
    "\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "            pass\n",
    "\n",
    "        outputTxtPath = self.output_dir+\"xview_img_{}.txt\".format(set_str)\n",
    "\n",
    "        if os.path.exists(outputTxtPath):\n",
    "            os.remove(outputTxtPath)\n",
    "            pass\n",
    "        \n",
    "        with open(outputTxtPath, mode='w', encoding='utf-8') as myfile:\n",
    "            myfile.write('\\n'.join(lines))\n",
    "        pass\n",
    "\n",
    "    def transformDatum(self,datum,res_out=30):\n",
    "        \"\"\"\n",
    "        takes in as input list of tuples corresponding to\n",
    "        first string of subset, and training file indexes\n",
    "        (\"train\", [training file idxs])\n",
    "        \"\"\"\n",
    "        for (data_str, data_files) in datum:\n",
    "            self.exportChipImages(data_files,self.output_dir,data_str,res_out=res_out)            \n",
    "            pass\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
